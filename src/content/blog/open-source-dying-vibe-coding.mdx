---
title: "Open Source Is Dying and Vibe Coding Is Holding the Pillow"
description: "cURL killed its bug bounty. Tldraw closed all external PRs. Ghostty bans AI contributors. Tailwind laid off 75% of its engineers after an 80% revenue drop. The open source ecosystem is suffocating under AI-generated slop — and the people keeping the internet running are walking away."
pubDate: 2026-02-28
tags: ["Vibe Coding", "AI", "Development"]
author: "Mario"
coverImage: "/images/blog/open-source-crisis-cover.svg"
coverImageAlt: "Open Source Is Dying - The crisis of AI-generated contributions overwhelming maintainers"
---

Exactly one year ago today, Andrej Karpathy fired off what he later called "a shower of thoughts throwaway tweet." It went something like this:

**"There's a new kind of coding I call 'vibe coding', where you fully give in to the vibes, embrace exponentials, and forget that the code even exists."**

4.5 million views. Collins Dictionary's Word of the Year. A generation of developers adopting the philosophy. And an open source ecosystem that's now choking on the consequences.

I want to be very clear about something before we go any further: **I use AI coding tools every single day.** Claude Code is the backbone of my workflow. I've written multiple blog posts on this site about how Opus 4.6 changed my life. This is not an anti-AI article.

This is an article about what happens when millions of people start vibe coding against open source projects maintained by humans who were already burning out before AI entered the picture. And the answer, based on what happened in January and February 2026, is: those humans are leaving.

---

## The Body Count

Let me just lay out what happened in the past eight weeks. Not opinions. Not predictions. Things that actually happened.

### cURL Killed Its Bug Bounty

Daniel Stenberg — the guy who created cURL, the tool that basically every device on the internet uses — shut down cURL's bug bounty program on HackerOne. Effective February 1, 2026.

The reason? AI-generated vulnerability reports had reached **20% of all submissions**, and the overall valid-report rate had dropped to **5%**. Five percent. That means for every twenty reports the security team had to read, review, and respond to, nineteen were garbage. And of those nineteen, a growing chunk were AI-generated garbage that *sounded* authoritative and *looked* legitimate but described vulnerabilities that didn't exist.

Stenberg's exact words: **"The main goal with shutting down the bounty is to remove the incentive for people to submit crap and non-well-researched reports to us."**

After $86,000 in total payouts over the program's lifetime, cURL moved to accepting vulnerability reports through GitHub only — no bounty, no reward, just the satisfaction of actually helping. Funny how removing the money is the only way to filter out the people who don't actually care about the code.

### Tldraw Closed All External Pull Requests

On January 15, 2026, Steve Ruiz — creator of tldraw, the open source infinite canvas SDK — posted this:

**"This week we're going to begin automatically closing pull requests from external contributors. I hate this, sorry."**

The problem wasn't that AI-generated PRs were obviously bad. That would've been easy to handle. The problem was they *looked good*. They were formally correct. Tests passed. The code compiled. And the tldraw team had started merging some of them before they noticed the patterns: authors ignoring the PR template, large PRs abandoned when authors wouldn't sign the CLA, commits spaced with suspiciously brief gaps, authors with dozens of PRs across dozens of unrelated repositories.

Here's the part that made me put my phone down and stare at the ceiling for a while. Ruiz had been using Claude Code to turn quick notes like "fix bug in sidebar" into well-formed GitHub issues. Other people's AI tools were then picking up those issues and generating PRs from them. **AI was writing issues. AI was writing the code to fix those issues. Humans were doing none of the work and all of the reviewing.**

Ruiz's conclusion hit like a truck: **"When code was hard to write and low-effort work was easy to identify, it was worth the cost to review the good stuff. If code is easy to write and bad work is virtually indistinguishable from good, then the value of external contribution is probably less than zero."**

Read that again. The value of external contribution is *probably less than zero*. From the maintainer of one of the most respected open source projects on GitHub.

### Ghostty Went Zero Tolerance

Mitchell Hashimoto — co-founder of HashiCorp, creator of Terraform, and now building Ghostty — took a different approach. In August 2025, he introduced mandatory disclosure: if you used AI in any form while contributing to Ghostty, you had to say so in the PR.

The result? **Fifty percent of all pull requests included an AI disclosure.** Half. Of all contributions.

By January 2026, Hashimoto escalated to zero tolerance. Ghostty's `AI_POLICY.md` now reads like a terms of service written by someone who's had enough:

- All AI usage must be disclosed, including the specific tool used
- You must fully understand all code you submit — if you can't explain it without AI, don't contribute
- AI-generated PRs are only allowed for accepted issues
- Drive-by contributions get closed immediately
- **Repeat offenders will be permanently banned**

Hashimoto isn't anti-AI. He uses AI tools himself. His maintainers are exempt from these rules. The policy exists because the people submitting AI-generated code to Ghostty *don't understand the code they're submitting*. They can't answer follow-up questions. They can't fix edge cases the AI missed. They're not contributing — they're dumping.

### Tailwind Lost 80% of Its Revenue and 75% of Its Engineers

This one hurt to write.

On January 6, 2026, Adam Wathan — founder of Tailwind CSS, the framework that half the web is built on — laid off three of his four engineers. In a GitHub comment, he said:

**"The reality is that 75% of the people on our engineering team lost their jobs here yesterday because of the brutal impact AI has had on our business."**

And then the kicker:

**"Tailwind is growing faster than it ever has and is bigger than it ever has been, and our revenue is down close to 80%."**

Let that contradiction marinate. The most popular CSS framework in the world. More downloads than ever. More users than ever. And revenue down 80%.

The mechanism is brutally simple. Tailwind's business model relied on developers visiting their documentation, discovering commercial products like Tailwind Plus, and occasionally buying them. But AI coding assistants now answer Tailwind questions directly in the IDE. Developers get what they need without ever visiting the site. **Docs traffic dropped 40% since early 2023.** The funnel that paid the bills doesn't exist anymore.

When a contributor tried to create an `llms.txt` file — a text-only version of the docs specifically designed for AI consumption — Wathan closed the PR. From a business perspective, making the documentation more AI-friendly would've been like handing out the keys to his own coffin.

Wathan's forecast: if nothing changed, the company would be unable to meet payroll within six months.

After the news broke, Vercel, Google AI Studio, Gumroad, and others rushed to sponsor the project. The Hacker News thread hit 1,100 points and 635 comments. But sponsorships are band-aids. The business model is gone.

---

## The Numbers Behind the Collapse

Let me zoom out from individual stories and look at the data.

**Stack Overflow activity is down 25%** since ChatGPT launched. The platform that was the backbone of developer knowledge-sharing for fifteen years is hemorrhaging engagement. Developers aren't asking questions on Stack Overflow because they're asking AI instead. And they're not answering questions on Stack Overflow because... well, because fewer people are asking.

**60% of open source maintainers are unpaid.** That was true before AI. Now add the flood of AI-generated issues, bug reports, and PRs that these unpaid volunteers have to review.

**60% of maintainers have quit or considered quitting.** Up from 58% the year before. **44% cite burnout specifically.** And the percentage saying they're not getting paid enough rose from 32% to 38%.

**Kubernetes retired Ingress NGINX** — one of the most widely used components in the entire ecosystem — due to maintainer burnout. Not deprecated. Retired. No more security updates. If you're running it (and you probably are), you're on your own.

Someone described the situation as **"a denial of service attack on human attention."** I can't think of a better way to put it.

---

## The Uncomfortable Truth About Vibe Coding

Here's where I have to be honest about my own complicity.

I vibe code. I love it. I've written thousands of words on this site about how Claude Code and Opus 4.6 transformed my iOS development workflow. I've sent coding commands from the tram. I've refactored networking layers while buying groceries. I meant every word.

But there's a difference between vibe coding in your own codebase — where you understand the architecture, where you review the output, where you own the consequences — and vibe coding *at* someone else's project. The first is a productivity tool. The second is vandalism with extra steps.

And that's what's happening. People are pointing AI tools at open source repos, generating PRs they don't understand, and walking away. They get to pad their GitHub contribution graph. The maintainer gets to spend their unpaid Saturday reviewing garbage. Everybody wins except the person doing the actual work.

Karpathy himself seems to have recognized this. A year after coining the term, he's now suggesting **"agentic engineering"** as the proper name for what professionals do — emphasizing that "there is an art and science and expertise to it." Vibe coding, in his framing, is for throwaway weekend projects. Not for production code. And definitely not for other people's projects.

### The METR Study Nobody Wants to Talk About

In July 2025, METR (a well-respected AI evaluation organization) published a randomized controlled trial that should've been a wake-up call. They tracked 16 experienced open source developers completing 246 real-world coding tasks on mature repositories — codebases averaging over a million lines of code where the developers had an average of 5 years of experience.

The finding? **When allowed to use AI tools, developers were 19% slower.**

Not faster. Slower.

But here's the part that keeps me up at night: **before the study, developers predicted AI would make them 24% faster. After the study, they still believed AI had made them 20% faster.** The actual measured result was 19% slower, and the developers *could not feel the difference*.

METR's researchers put it bluntly: **"When people report that AI has accelerated their work, they might be wrong."**

The study used Cursor Pro with Claude 3.5/3.7 Sonnet — not bad tools. And the developers reported spending significant time reviewing and cleaning up AI output, introducing what the researchers called "extra cognitive load and context-switching."

Now, this study has caveats. These were experienced developers in codebases they knew inside out — exactly the scenario where AI has the least room to help. For less experienced developers in unfamiliar codebases, the results might be different. But it demolishes the narrative that AI tools universally make everyone faster at everything. Sometimes you're slower and you don't even know it.

---

## The BBC Hack That Should Scare You

In February 2026, cybersecurity researcher Etizaz Mohsin demonstrated something to BBC journalist Joe Tidy that perfectly illustrates the security dimension of all this.

Tidy used Orchids — a vibe coding platform with a million users — to build a simple computer game. Mohsin exploited a security flaw to gain access to Tidy's project, added a single line of code somewhere in the thousands of AI-generated lines, and took control of the laptop. A notepad file called "Joe is hacked" appeared on the desktop. The wallpaper changed to an image of an AI hacker.

Zero clicks from Tidy. He didn't download anything. He didn't approve anything. He was hacked through code he never wrote and never read.

This is what happens when you combine "forget that the code even exists" with production systems. The code still exists. It still runs. It still has security implications. And if nobody's reading it — not the person who "wrote" it, not the AI that generated it, not the maintainer who merged it — then nobody's catching the vulnerabilities.

---

## What Actually Needs to Happen

I don't have a perfect solution. Nobody does. But I know what definitely isn't working.

**GitHub needs to build better tools for maintainers.** Steve Ruiz said his auto-close policy was "temporary until GitHub provides better tools for managing contributions." GitHub profits enormously from open source — their entire Copilot product is trained on open source code. They owe the community something better than the current PR review interface that was designed for a world where humans wrote code.

**The "contribution = code" model needs to die.** Ruiz's insight was perfect: maybe the most valuable contribution in the AI era isn't code at all. It's identifying and clearly describing problems. Let the maintainers — who actually understand the codebase — decide how to fix them, with or without AI. Bug reports, reproductions, test cases, documentation — all of these are more valuable than a drive-by PR from someone who used AI to "fix" something they don't understand.

**Companies that profit from open source need to pay for it.** Tailwind's collapse isn't just a Tailwind problem. It's a preview of what happens to every open source project whose business model depends on documentation traffic. If your company uses open source frameworks, and your AI tools are the reason those frameworks can't pay their engineers, you have a moral obligation to sponsor them. Full stop. The Open Source Pledge exists. Use it.

**We need to stop pretending vibe coding has no costs.** I'm not going to stop using Claude Code. I'm not going to tell you to stop using it either. But I am going to be more honest about the fact that every time an AI tool answers a question I would've searched Stack Overflow for, every time it generates code I would've learned from the docs, every time it writes a PR I wouldn't have submitted myself — there's a cost being paid somewhere. By a maintainer. By a business. By the next developer who won't learn the thing I skipped.

---

## The Part Where I Don't End With a Summary

I started this post intending to write about the cURL bug bounty. Just that one story. But as I pulled on the thread, it kept unraveling.

cURL. Tldraw. Ghostty. Tailwind. Stack Overflow. Kubernetes. The maintainer surveys. The METR study. The BBC hack. Each story individually is concerning. Together, they paint a picture of an ecosystem in genuine crisis.

The people who maintain the infrastructure that the entire software industry runs on — for free, on their weekends, with no recognition and no compensation — are being buried under an avalanche of AI-generated noise. And the industry's response so far has been to build more AI tools that generate more noise.

Karpathy was right about one thing: there is a new kind of coding. But the vibes aren't reaching the people holding the pillows over open source's face. For them, there are no vibes. Just more PRs to close, more reports to reject, and one more Tuesday wondering if it's worth continuing.

The code still exists. The question is whether the humans behind it will.

Happy coding. ✦
