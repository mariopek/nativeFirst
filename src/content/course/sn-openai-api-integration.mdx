---
title: "OpenAI API Integration"
description: "Build a production networking layer for the OpenAI API with async/await, secure Keychain storage for API keys, structured request/response models, and robust error handling with retry logic."
courseSlug: "ship-native"
module: 4
moduleTitle: "AI Integration"
lesson: 1
duration: "26 min read"
difficulty: "intermediate"
topics: ["OpenAI API", "Networking", "Keychain", "async/await", "Error Handling", "Retry Logic", "API Security", "Moodbit"]
author: "Mario"
draft: false
pubDate: 2026-02-22
---

Moodbit has a data layer, a UI, and a persistence strategy. Users can log moods and see their entries on a timeline. It works — but it is not smart yet. This is the lesson where Moodbit gets a brain.

We are going to integrate the OpenAI Chat Completion API to analyze mood journal entries and return structured sentiment data. The API will read what the user wrote, classify the sentiment, extract key themes, and generate a short insight. All of this happens over HTTPS, so we need a proper networking layer — one that handles authentication securely, decodes structured responses, retries on transient failures, and fails gracefully when things go wrong.

This is real-world networking. Not a toy example with JSONPlaceholder. A production integration with an API that costs money per call, rate-limits aggressively, and returns complex nested JSON. If you get this right, you can integrate any API.

## What You'll Learn

- Build an `OpenAIService` that calls the Chat Completion endpoint using async/await and URLSession
- Store the API key securely in the iOS Keychain — never in UserDefaults, never hardcoded
- Define structured Codable request and response models that match the OpenAI API exactly
- Implement typed error handling with Swift 6 typed throws and automatic retry with exponential backoff

## Why This Matters

Every AI-powered feature in a production app depends on the same foundation: a secure, resilient networking layer. If you hardcode your API key, it gets scraped from your binary within days. If you skip retry logic, users on flaky cellular connections see errors constantly. If your error types are stringly-typed, debugging production issues becomes guesswork.

The patterns in this lesson are not OpenAI-specific. They transfer to any authenticated API — Anthropic, Google Cloud, your own backend. Learn them once, use them everywhere.

## Plan Phase: Defining What We Build

Open Claude Code in your Moodbit project directory and send this planning prompt:

```
I need to integrate the OpenAI Chat Completion API into our Moodbit
mood journal app. Before writing code, plan the implementation.

Context:
- Moodbit is a SwiftUI app using MVVM + Repository, Swift 6,
  SwiftData, targeting iOS 17+
- We need to send a mood journal entry (user text) to GPT and
  receive structured sentiment analysis back
- The response should include: sentiment (positive/neutral/negative),
  a confidence score (0.0–1.0), up to 3 key themes, and a short
  AI-generated insight (1-2 sentences)

Plan these files:
1. APIError.swift — typed error enum for all failure modes
2. KeychainHelper.swift — secure storage for the API key
3. ChatMessage.swift — Codable request/response models matching
   the OpenAI API
4. OpenAIService.swift — async service with retry logic

For each file, list the types and methods. Do not write code yet.
```

Claude Code will produce a structured plan. Review it for a few things.

**Check the model separation.** You want raw API models (matching OpenAI's JSON exactly) and a domain model (the `SentimentResult` your app actually uses). If the plan lumps them together, push back — API schemas change, and you do not want that rippling through your views.

**Check the error cases.** You need at minimum: invalid API key, rate limited (429), server error (5xx), network unreachable, decoding failure, and empty response. If the plan is missing rate limiting, add it — OpenAI enforces hard limits and you will hit them during development.

**Check the Keychain approach.** If the plan suggests UserDefaults, Environment variables at runtime, or a hardcoded string, reject it immediately.

### The Anti-Pattern

Here is what bad OpenAI integration looks like — and what AI will generate if you prompt lazily:

```swift
// DO NOT DO THIS
let apiKey = "sk-proj-abc123..." // Hardcoded. Scraped in hours.

let json = try JSONSerialization.jsonObject(with: data) as! [String: Any] // Force cast. Crash.
let content = (json["choices"] as! [[String: Any]])[0]["message"] // Force unwrap. Crash.

// No error handling. No retry. No typed errors.
// This code will cost you money and crash in production.
```

Hardcoded keys get extracted from your app binary with trivial tooling. Force-unwrapping JSON crashes the moment OpenAI changes their response format — which they do. No retry logic means every transient network hiccup becomes a user-visible error. We are going to do better.

## Execute Phase: Implementation

Now send the execution prompt:

```
Implement the OpenAI integration for Moodbit. Follow our CLAUDE.md
conventions (Swift 6, strict concurrency, @Observable, os.Logger).

Create these files in order:

1. Services/API/APIError.swift
   - Enum with typed throws (Swift 6)
   - Cases: invalidURL, invalidAPIKey, httpError(statusCode: Int),
     rateLimited(retryAfter: TimeInterval?), decodingFailed(Error),
     networkUnavailable, emptyResponse, underlying(Error)
   - Conform to LocalizedError with user-friendly descriptions

2. Helpers/KeychainHelper.swift
   - save(key:data:), read(key:) -> Data?, delete(key:)
   - Use Security framework directly (no third-party wrapper)
   - Convenience methods: saveAPIKey(_:), readAPIKey() -> String?

3. Models/API/ChatMessage.swift
   - ChatCompletionRequest: model, messages array, temperature,
     max_tokens
   - ChatCompletionResponse: id, choices array with message content
   - Message: role (system/user/assistant), content
   - All Codable, matching OpenAI's exact JSON schema

4. Services/API/OpenAIService.swift
   - init with baseURL and KeychainHelper
   - analyzeSentiment(text:) async throws(APIError) -> SentimentResult
   - Private: performRequest, buildRequest, parseResponse
   - Retry logic: 3 attempts, exponential backoff, only on 429/5xx
   - Rate limit awareness: respect Retry-After header

Also create Models/SentimentResult.swift — our domain model with
sentiment (enum), confidence (Double), themes ([String]),
insight (String).
```

Review the AI output carefully. Here is what to look for:

- **APIError.swift** — Does it conform to `LocalizedError`? Does the `rateLimited` case carry an optional `retryAfter` value? These details matter for retry logic downstream.
- **KeychainHelper.swift** — Does it use `SecItemAdd`, `SecItemCopyMatching`, `SecItemDelete` from the Security framework? If it imports any third-party Keychain library, reject it. The Security framework is four functions. You do not need a wrapper.
- **ChatMessage.swift** — Does the request model use `CodingKeys` to map `maxTokens` to `max_tokens`? OpenAI's API uses snake_case. Swift uses camelCase. If there are no `CodingKeys`, the request will serialize wrong and the API will reject it.
- **OpenAIService.swift** — Does retry logic check the status code before retrying? Retrying a 401 (bad API key) is pointless. Only 429 (rate limit) and 5xx (server error) should retry.

## Iteration

After reviewing the initial output, send this follow-up to tighten the implementation:

```
Good foundation. Refine these things:

1. In OpenAIService, the system prompt for sentiment analysis
   should instruct GPT to respond in a strict JSON format:
   {"sentiment": "positive", "confidence": 0.85,
    "themes": ["gratitude", "progress"], "insight": "..."}
   Parse this from the message content string, not from the
   top-level API response.

2. Add a Sendable conformance to OpenAIService so it can be
   safely used from any actor context.

3. KeychainHelper should use kSecAttrAccessible:
   kSecAttrAccessibleAfterFirstUnlockThisDeviceOnly — the API key
   should survive backgrounding but not device backups.

4. Add os.Logger to OpenAIService. Log request start, retry
   attempts, and failures at appropriate levels (debug, info,
   error). Never log the API key.
```

This iteration catches the things AI usually misses: the Keychain accessibility level (critical for security), the Sendable conformance (required for Swift 6 strict concurrency), and the logging discipline (never log secrets).

## Verify Phase

Before moving on, verify these things manually:

1. **Build the project.** Zero warnings, zero errors. Swift 6 strict concurrency should not complain about any of these types.
2. **Check the Keychain accessibility.** Open `KeychainHelper.swift` and confirm it uses `kSecAttrAccessibleAfterFirstUnlockThisDeviceOnly`, not `kSecAttrAccessibleAlways` or nothing at all.
3. **Check CodingKeys.** Open `ChatMessage.swift` and verify that `maxTokens` maps to `max_tokens`, and any other snake_case fields are handled.
4. **Check retry logic.** Read `OpenAIService.swift` and confirm it only retries on 429 and 5xx. Confirm it reads the `Retry-After` header on 429 responses. Confirm the backoff is exponential (1s, 2s, 4s), not linear.
5. **Check that the API key is never hardcoded.** Search the entire project for `sk-`. There should be zero results.

## Final Code

Here is the complete, production-quality implementation. Every file compiles with Swift 6 strict concurrency enabled.

### APIError.swift

```swift
import Foundation

enum APIError: Error, LocalizedError, Sendable {
    case invalidURL
    case invalidAPIKey
    case httpError(statusCode: Int)
    case rateLimited(retryAfter: TimeInterval?)
    case decodingFailed(Error)
    case networkUnavailable
    case emptyResponse
    case underlying(Error)

    var errorDescription: String? {
        switch self {
        case .invalidURL:
            "The request URL could not be constructed."
        case .invalidAPIKey:
            "Your API key is missing or invalid. Add it in Settings."
        case .httpError(let statusCode):
            "The server returned an error (HTTP \(statusCode))."
        case .rateLimited:
            "Too many requests. Please wait a moment and try again."
        case .decodingFailed:
            "The server response could not be read."
        case .networkUnavailable:
            "No internet connection. Check your network and try again."
        case .emptyResponse:
            "The server returned an empty response."
        case .underlying(let error):
            error.localizedDescription
        }
    }

    var isRetryable: Bool {
        switch self {
        case .rateLimited, .networkUnavailable:
            true
        case .httpError(let code):
            code >= 500
        default:
            false
        }
    }
}
```

### KeychainHelper.swift

```swift
import Foundation
import Security

struct KeychainHelper: Sendable {
    private static let serviceName = "com.moodbit.api"

    // MARK: - Generic Operations

    static func save(key: String, data: Data) -> Bool {
        delete(key: key)

        let query: [String: Any] = [
            kSecClass as String: kSecClassGenericPassword,
            kSecAttrService as String: serviceName,
            kSecAttrAccount as String: key,
            kSecValueData as String: data,
            kSecAttrAccessible as String: kSecAttrAccessibleAfterFirstUnlockThisDeviceOnly
        ]

        let status = SecItemAdd(query as CFDictionary, nil)
        return status == errSecSuccess
    }

    static func read(key: String) -> Data? {
        let query: [String: Any] = [
            kSecClass as String: kSecClassGenericPassword,
            kSecAttrService as String: serviceName,
            kSecAttrAccount as String: key,
            kSecReturnData as String: true,
            kSecMatchLimit as String: kSecMatchLimitOne
        ]

        var result: AnyObject?
        let status = SecItemCopyMatching(query as CFDictionary, &result)

        guard status == errSecSuccess else { return nil }
        return result as? Data
    }

    @discardableResult
    static func delete(key: String) -> Bool {
        let query: [String: Any] = [
            kSecClass as String: kSecClassGenericPassword,
            kSecAttrService as String: serviceName,
            kSecAttrAccount as String: key
        ]

        let status = SecItemDelete(query as CFDictionary)
        return status == errSecSuccess || status == errSecItemNotFound
    }

    // MARK: - API Key Convenience

    private static let apiKeyAccount = "openai-api-key"

    static func saveAPIKey(_ key: String) -> Bool {
        guard let data = key.data(using: .utf8) else { return false }
        return save(key: apiKeyAccount, data: data)
    }

    static func readAPIKey() -> String? {
        guard let data = read(key: apiKeyAccount) else { return nil }
        return String(data: data, encoding: .utf8)
    }

    static func deleteAPIKey() -> Bool {
        delete(key: apiKeyAccount)
    }
}
```

### ChatMessage.swift

```swift
import Foundation

// MARK: - Request Models

struct ChatCompletionRequest: Encodable, Sendable {
    let model: String
    let messages: [ChatMessage]
    let temperature: Double
    let maxTokens: Int

    enum CodingKeys: String, CodingKey {
        case model, messages, temperature
        case maxTokens = "max_tokens"
    }
}

struct ChatMessage: Codable, Sendable {
    let role: Role
    let content: String

    enum Role: String, Codable, Sendable {
        case system
        case user
        case assistant
    }
}

// MARK: - Response Models

struct ChatCompletionResponse: Decodable, Sendable {
    let id: String
    let choices: [Choice]
    let usage: Usage

    struct Choice: Decodable, Sendable {
        let index: Int
        let message: ChatMessage
        let finishReason: String?

        enum CodingKeys: String, CodingKey {
            case index, message
            case finishReason = "finish_reason"
        }
    }

    struct Usage: Decodable, Sendable {
        let promptTokens: Int
        let completionTokens: Int
        let totalTokens: Int

        enum CodingKeys: String, CodingKey {
            case promptTokens = "prompt_tokens"
            case completionTokens = "completion_tokens"
            case totalTokens = "total_tokens"
        }
    }
}

// MARK: - Domain Model

struct SentimentResult: Sendable {
    let sentiment: Sentiment
    let confidence: Double
    let themes: [String]
    let insight: String

    enum Sentiment: String, Codable, Sendable {
        case positive
        case neutral
        case negative
    }
}

/// Raw JSON shape we ask GPT to return inside the message content.
private struct SentimentPayload: Decodable {
    let sentiment: SentimentResult.Sentiment
    let confidence: Double
    let themes: [String]
    let insight: String

    func toDomain() -> SentimentResult {
        SentimentResult(
            sentiment: sentiment,
            confidence: min(max(confidence, 0), 1),
            themes: Array(themes.prefix(3)),
            insight: insight
        )
    }
}
```

### OpenAIService.swift

```swift
import Foundation
import os

final class OpenAIService: Sendable {
    private let baseURL: String
    private let session: URLSession
    private let decoder: JSONDecoder
    private let encoder: JSONEncoder
    private let logger = Logger(subsystem: "com.moodbit", category: "OpenAIService")

    private let maxRetries = 3
    private let initialBackoff: TimeInterval = 1.0

    init(
        baseURL: String = "https://api.openai.com",
        session: URLSession = .shared
    ) {
        self.baseURL = baseURL
        self.session = session

        let decoder = JSONDecoder()
        decoder.keyDecodingStrategy = .convertFromSnakeCase
        self.decoder = decoder

        let encoder = JSONEncoder()
        self.encoder = encoder
    }

    // MARK: - Public API

    func analyzeSentiment(text: String) async throws(APIError) -> SentimentResult {
        guard let apiKey = KeychainHelper.readAPIKey(), !apiKey.isEmpty else {
            throw .invalidAPIKey
        }

        let systemPrompt = """
        You are a sentiment analysis engine for a mood journal app. \
        Analyze the user's journal entry and respond with ONLY a JSON object \
        in this exact format, no markdown, no explanation:
        {"sentiment":"positive","confidence":0.85,"themes":["gratitude","progress"],"insight":"A brief 1-2 sentence insight."}

        Rules:
        - sentiment must be exactly one of: positive, neutral, negative
        - confidence is a Float between 0.0 and 1.0
        - themes is an array of 1-3 single-word or short-phrase strings
        - insight is 1-2 sentences, empathetic and encouraging
        """

        let request = ChatCompletionRequest(
            model: "gpt-4o-mini",
            messages: [
                ChatMessage(role: .system, content: systemPrompt),
                ChatMessage(role: .user, content: text)
            ],
            temperature: 0.3,
            maxTokens: 200
        )

        let response: ChatCompletionResponse = try await performRequest(
            path: "/v1/chat/completions",
            body: request,
            apiKey: apiKey
        )

        return try parseResponse(response)
    }

    // MARK: - Networking

    private func performRequest<RequestBody: Encodable, ResponseBody: Decodable>(
        path: String,
        body: RequestBody,
        apiKey: String
    ) async throws(APIError) -> ResponseBody {
        let urlRequest: URLRequest
        do {
            urlRequest = try buildRequest(path: path, body: body, apiKey: apiKey)
        } catch let error as APIError {
            throw error
        } catch {
            throw .underlying(error)
        }

        var lastError: APIError = .emptyResponse

        for attempt in 0..<maxRetries {
            if attempt > 0 {
                logger.info("Retry attempt \(attempt) of \(self.maxRetries - 1)")
            }

            do {
                let (data, response) = try await session.data(for: urlRequest)

                guard let httpResponse = response as? HTTPURLResponse else {
                    throw APIError.emptyResponse
                }

                logger.debug("HTTP \(httpResponse.statusCode) for \(path)")

                switch httpResponse.statusCode {
                case 200...299:
                    do {
                        return try decoder.decode(ResponseBody.self, from: data)
                    } catch {
                        throw APIError.decodingFailed(error)
                    }

                case 401:
                    throw APIError.invalidAPIKey

                case 429:
                    let retryAfter = httpResponse.value(forHTTPHeaderField: "Retry-After")
                        .flatMap { TimeInterval($0) }
                    let error = APIError.rateLimited(retryAfter: retryAfter)

                    if attempt < maxRetries - 1 {
                        let delay = retryAfter ?? (initialBackoff * pow(2.0, Double(attempt)))
                        logger.info("Rate limited. Waiting \(delay)s before retry.")
                        try? await Task.sleep(for: .seconds(delay))
                        lastError = error
                        continue
                    }
                    throw error

                case 500...599:
                    let error = APIError.httpError(statusCode: httpResponse.statusCode)

                    if attempt < maxRetries - 1 {
                        let delay = initialBackoff * pow(2.0, Double(attempt))
                        logger.info("Server error \(httpResponse.statusCode). Waiting \(delay)s before retry.")
                        try? await Task.sleep(for: .seconds(delay))
                        lastError = error
                        continue
                    }
                    throw error

                default:
                    throw APIError.httpError(statusCode: httpResponse.statusCode)
                }

            } catch let error as APIError {
                if !error.isRetryable || attempt >= maxRetries - 1 {
                    throw error
                }
                lastError = error
            } catch let urlError as URLError where urlError.code == .notConnectedToInternet
                || urlError.code == .networkConnectionLost {
                let error = APIError.networkUnavailable
                if attempt >= maxRetries - 1 {
                    throw error
                }
                lastError = error
                let delay = initialBackoff * pow(2.0, Double(attempt))
                try? await Task.sleep(for: .seconds(delay))
            } catch {
                throw APIError.underlying(error)
            }
        }

        throw lastError
    }

    private func buildRequest<Body: Encodable>(
        path: String,
        body: Body,
        apiKey: String
    ) throws -> URLRequest {
        guard let url = URL(string: baseURL + path) else {
            throw APIError.invalidURL
        }

        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        request.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")
        request.timeoutInterval = 30

        do {
            request.httpBody = try encoder.encode(body)
        } catch {
            throw APIError.underlying(error)
        }

        return request
    }

    // MARK: - Response Parsing

    private func parseResponse(_ response: ChatCompletionResponse) throws(APIError) -> SentimentResult {
        guard let content = response.choices.first?.message.content else {
            throw .emptyResponse
        }

        logger.debug("Token usage — prompt: \(response.usage.promptTokens), completion: \(response.usage.completionTokens)")

        guard let jsonData = content.data(using: .utf8) else {
            throw .decodingFailed(
                DecodingError.dataCorrupted(
                    .init(codingPath: [], debugDescription: "Content is not valid UTF-8")
                )
            )
        }

        do {
            let payload = try JSONDecoder().decode(SentimentPayload.self, from: jsonData)
            return payload.toDomain()
        } catch {
            logger.error("Failed to parse sentiment JSON from GPT content: \(content)")
            throw .decodingFailed(error)
        }
    }
}
```

A few things worth calling out in this implementation.

**The `SentimentPayload` is private.** The rest of the app never sees it. It exists solely to decode GPT's JSON content string into a `SentimentResult`. If OpenAI changes their response format, you update `ChatCompletionResponse`. If you change how you prompt GPT, you update `SentimentPayload`. Neither change touches your views or view models.

**The system prompt asks for raw JSON, no markdown.** GPT models love wrapping JSON in triple-backtick code fences. The explicit instruction "no markdown, no explanation" prevents that. If you skip this, you will get ````json\n{...}\n```` back and your decoder will choke.

**Temperature is 0.3.** For classification tasks, you want low temperature — consistent, predictable outputs. Creative writing uses 0.7-1.0. Sentiment analysis is not creative.

**`gpt-4o-mini`** is the model. It is cheap (fractions of a cent per call), fast (under 2 seconds typically), and more than capable enough for sentiment classification. Do not use `gpt-4o` for this — it is slower, more expensive, and overkill for structured extraction tasks.

**Retry only fires on 429 and 5xx.** A 401 means your key is wrong — retrying will not fix it. A 400 means your request is malformed — retrying will not fix it. Only transient errors (rate limits, server hiccups) get retried. This is a decision most tutorials get wrong.

## Checkpoint

Before moving to the next lesson, confirm all of the following:

- [ ] Project builds with zero warnings under Swift 6 strict concurrency
- [ ] `APIError` conforms to both `Error` and `Sendable`
- [ ] `KeychainHelper` uses `kSecAttrAccessibleAfterFirstUnlockThisDeviceOnly`
- [ ] `ChatCompletionRequest` has `CodingKeys` mapping `maxTokens` to `max_tokens`
- [ ] `OpenAIService.analyzeSentiment` uses typed throws (`throws(APIError)`)
- [ ] Retry logic only retries on 429 and 5xx status codes
- [ ] The `Retry-After` header is respected on 429 responses
- [ ] Searching the project for `sk-` returns zero results
- [ ] The API key is read from `KeychainHelper`, never passed as a parameter from the UI layer

## Challenge

**Add a token budget guard.** Before sending a request, estimate the token count of the user's journal entry (rough heuristic: 1 token per 4 characters in English). If the entry would exceed a configurable maximum (say 1000 tokens), return a new `APIError.inputTooLong(estimatedTokens: Int, limit: Int)` case instead of making the network call. This prevents wasting money on entries that will be truncated by the `max_tokens` limit anyway.

*Hint:* Add the estimation as a private method on `OpenAIService`. The check goes at the top of `analyzeSentiment(text:)`, before you even read the API key. Add the new case to `APIError` with a user-friendly description like "Your entry is too long for analysis. Try shortening it."
