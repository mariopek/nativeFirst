---
title: "Performance Optimization"
description: "Optimize Moodbit for production ‚Äî lazy loading, SwiftData query tuning, image caching, launch time reduction, and background processing patterns that keep your app fast."
courseSlug: "ship-native"
module: 7
moduleTitle: "Production Polish"
lesson: 3
duration: "20 min read"
difficulty: "advanced"
topics: ["Performance", "LazyVStack", "SwiftData Optimization", "Image Caching", "Launch Time", "Background Processing", "Pagination", "Moodbit"]
author: "Mario"
draft: false
pubDate: 2026-02-22
---

Moodbit works. The error handling is solid. The accessibility is polished. A user with twelve entries opens the app and everything feels instant. That same user logs moods for a year, accumulates 800 entries, opens the app on a cold morning, and the launch takes three seconds. They scroll through their mood history and every swipe hitches. They tap the Insights tab and the chart takes a full second to appear.

They do not file a bug. They do not leave a review. They delete your app and try another one.

Performance is the feature nobody sees until it is missing. In this lesson, we measure what is actually slow, fix it with targeted optimizations, and verify that every change made things faster ‚Äî not just different. No guessing. No premature optimization. Instruments first, code changes second.

## What You'll Learn

- Replace `VStack` with `LazyVStack` and paginate mood history with `FetchDescriptor` so only 50 entries load at a time instead of the entire database
- Optimize SwiftData queries with `#Predicate`, `fetchLimit`, `fetchOffset`, and `SortDescriptor` to eliminate unnecessary memory allocations at scale
- Build an image cache for mood entry photos so the same thumbnail never decodes from disk twice during a scroll session
- Reduce launch time by deferring non-critical work and moving AI insight generation to background tasks with Swift concurrency

## Why This Matters

Apple measures your app's launch time. If a cold start exceeds 4 seconds, the watchdog kills the process ‚Äî the user sees a crash. The App Store review team tests on older hardware. A sluggish iPhone SE experience is a rejection risk.

Beyond Apple's threshold: every 100ms of delay reduces user engagement measurably. Moodbit talks to an external AI service, reads from a local database, renders charts, and ‚Äî if users attach photos ‚Äî decodes images. Each of those is a potential bottleneck. Let us find out which ones actually are, and fix only what matters.

## Plan Phase: Profiling Before Optimizing

The single most important rule of performance work: measure first. Send this prompt:

```
I need to optimize Moodbit's performance before shipping.
Do NOT write code yet ‚Äî create a profiling and optimization plan.

Current architecture:
- SwiftData for persistence (MoodEntry model with score, note,
  emoji, insight, date, insightSource, optional photoData)
- OpenAI API for insight generation (network call per entry)
- Charts framework for mood history visualization
- ~10 views, TabView navigation
- Some entries have attached photos stored as Data

Potential user scale:
- 1-3 entries per day
- After 1 year: ~500-1000 entries
- Power users: up to 2000+ entries
- ~30% of entries have a photo attachment

I suspect these bottlenecks but have NOT measured:
1. Loading all entries on app launch
2. The mood history list might be using VStack instead of LazyVStack
3. AI insight generation blocks the main thread
4. Chart rendering with 365+ data points
5. Photo thumbnails are decoded every scroll pass

Plan:
1. What should I measure first, and how?
2. What are the likely bottlenecks at 1000+ entries?
3. What optimizations should I apply in what order?
4. How do I verify each optimization actually helped?
```

### AI Plan Review

The AI should produce an ordered list of measurements before optimizations. That order is critical ‚Äî you need a baseline before changing anything.

**Keep** ‚Äî "Measure launch time with Instruments Time Profiler before changing anything." Correct. Without a baseline number, you cannot prove an optimization helped. You are just guessing.

**Keep** ‚Äî "Profile scroll performance at 1000+ entries with test data." The AI should suggest generating test data first, then profiling. Performance testing with 5 entries tells you nothing about production behavior.

**Keep** ‚Äî "Use os_signpost markers for each critical path." Signposts show up in Instruments as named intervals, so you can see exactly how long each operation takes. This is how you get hard numbers, not estimates.

**Question** ‚Äî If the AI jumps straight to "replace VStack with LazyVStack" without suggesting measurement first, push back. That is probably the right fix, but confirm with data. Premature optimization creates complexity without evidence it was needed.

### Anti-Pattern: Optimizing Without Measuring

```swift
// The developer "optimizes" by adding caching everywhere
// without knowing if caching is even the problem.

// They add a manual cache for mood entries:
private var cachedEntries: [MoodEntry]?

// They add a cache for formatted dates:
private var dateCache: [Date: String] = [:]

// They add a cache for chart data:
private var chartDataCache: [ChartDataPoint]?

// Result: more memory usage, stale data bugs, cache invalidation
// headaches, and the actual bottleneck (VStack with 1000 items
// rendering all at once) is completely untouched.
```

The worst performance bugs come from fixing the wrong problem. Measure. Identify. Then fix.

## Execute Phase: Targeted Optimizations

First, generate test data so we can profile realistically:

```
Create a TestDataGenerator that populates SwiftData with realistic
mood entries for performance testing.

- Generate entries spanning 365 days
- 1-3 entries per day (random)
- Random mood scores weighted toward 5-8 (realistic distribution)
- Random emoji selection from the app's emoji set
- ~30% of entries have a photoData field with a small placeholder
  Data blob (simulate photo storage)
- Some entries have AI insights, some have on-device insights
- Total: roughly 700 entries

Put it in Debug/TestDataGenerator.swift. Only include it in
Debug builds using #if DEBUG.
```

```swift
#if DEBUG
import SwiftData
import Foundation

struct TestDataGenerator {
    static func populate(context: ModelContext) throws {
        let calendar = Calendar.current
        let today = Date.now
        let emojis = ["üòÑ", "üôÇ", "üòê", "üòï", "üò¢", "üò°", "üò∞", "üò¥", "ü§©", "üòå"]
        let notes: [String?] = [
            "Good day at work today",
            "Feeling stressed about the deadline",
            "Had a great workout this morning",
            "Could not sleep well last night",
            nil, nil, nil  // Weight toward no note
        ]
        // Small placeholder to simulate photo data (~10 KB)
        let placeholderPhoto = Data(repeating: 0xFF, count: 10_240)

        for dayOffset in 0..<365 {
            guard let date = calendar.date(
                byAdding: .day, value: -dayOffset, to: today
            ) else { continue }

            let entriesForDay = Int.random(in: 1...3)

            for i in 0..<entriesForDay {
                let hour = 8 + (i * 5) + Int.random(in: 0...3)
                let entryDate = calendar.date(
                    bySettingHour: hour,
                    minute: Int.random(in: 0...59),
                    second: 0, of: date
                ) ?? date

                let score = weightedRandomScore()
                let hasPhoto = Double.random(in: 0...1) < 0.3

                let entry = MoodEntry(
                    score: score,
                    note: notes.randomElement() ?? nil,
                    emoji: emojis.randomElement() ?? "üòê",
                    insight: "Sample insight for testing purposes.",
                    insightSource: Bool.random() ? .ai : .onDevice
                )
                entry.date = entryDate
                entry.photoData = hasPhoto ? placeholderPhoto : nil

                context.insert(entry)
            }
        }

        try context.save()
    }

    private static func weightedRandomScore() -> Int {
        let weights = [1, 2, 3, 5, 8, 12, 14, 12, 8, 5]
        let total = weights.reduce(0, +)
        var random = Int.random(in: 0..<total)
        for (index, weight) in weights.enumerated() {
            random -= weight
            if random < 0 { return index + 1 }
        }
        return 5
    }
}
#endif
```

Now, with 700+ test entries in the database, apply the optimizations. Send this prompt:

```
Optimize Moodbit for performance at scale (1000+ entries).
Apply these optimizations in order:

1. LAZY LOADING: Replace VStack with LazyVStack in
   MoodHistoryView. Use FetchDescriptor with fetchLimit and
   fetchOffset for true database-level pagination ‚Äî 50 entries
   per page, load more on scroll.

2. SWIFTDATA QUERY TUNING: Optimize the InsightsView @Query
   to fetch only the last 30 days with #Predicate. For the
   home screen entry count, use fetchCount() instead of
   fetching full objects.

3. IMAGE CACHING: Build an ImageCache actor that decodes
   thumbnail images once and holds them in an NSCache. The
   mood history row should check the cache before decoding.

4. BACKGROUND AI PROCESSING: Move the OpenAI API call off
   the main thread. Save the mood entry immediately with a
   placeholder insight, then update when the AI responds.

5. LAUNCH TIME: Defer non-critical initialization. Chart data
   and AI service setup should not happen until the user
   navigates to those screens. Add os_signpost markers to
   measure each phase.

Use Swift 6, strict concurrency, @Observable pattern.
```

### Code Review

**Optimization 1 ‚Äî LazyVStack with True Pagination:**

The before and after tells the whole story.

```swift
// BEFORE ‚Äî loads ALL entries into memory, renders ALL rows at once
struct MoodHistoryView: View {
    @Query(sort: \MoodEntry.date, order: .reverse)
    private var entries: [MoodEntry]

    var body: some View {
        ScrollView {
            VStack(spacing: 0) {                 // Every row created
                ForEach(entries) { entry in       // All 1000 entries
                    MoodEntryRow(entry: entry)    // in memory
                }
            }
        }
    }
}
```

The `@Query` fetches every `MoodEntry` from the database the moment this view appears. `VStack` creates all 1000 row views immediately. On a large dataset, this is an 800ms stall before the first frame renders.

```swift
// AFTER ‚Äî fetches 50 at a time, only visible rows exist
import SwiftUI
import SwiftData
import os

@Observable
final class MoodHistoryViewModel {
    private(set) var entries: [MoodEntry] = []
    private(set) var hasMore = true
    private(set) var isLoadingPage = false

    private var currentOffset = 0
    private let pageSize = 50
    private let context: ModelContext
    private let signposter = OSSignposter(
        subsystem: "com.moodbit", category: "Performance"
    )

    init(context: ModelContext) {
        self.context = context
    }

    func loadInitialPage() {
        let state = signposter.beginInterval("LoadInitialPage")
        defer { signposter.endInterval("LoadInitialPage", state) }

        currentOffset = 0
        entries = fetchPage(offset: 0)
        hasMore = entries.count == pageSize
    }

    func loadNextPage() {
        guard hasMore, !isLoadingPage else { return }
        isLoadingPage = true

        let state = signposter.beginInterval("LoadNextPage")
        defer {
            signposter.endInterval("LoadNextPage", state)
            isLoadingPage = false
        }

        currentOffset += pageSize
        let newEntries = fetchPage(offset: currentOffset)
        entries.append(contentsOf: newEntries)
        hasMore = newEntries.count == pageSize
    }

    private func fetchPage(offset: Int) -> [MoodEntry] {
        var descriptor = FetchDescriptor<MoodEntry>(
            sortBy: [SortDescriptor(\.date, order: .reverse)]
        )
        descriptor.fetchLimit = pageSize
        descriptor.fetchOffset = offset

        do {
            return try context.fetch(descriptor)
        } catch {
            return []
        }
    }
}
```

Review checklist:

- ‚úÖ `FetchDescriptor` with `fetchLimit` and `fetchOffset` ‚Äî the database returns only 50 rows per page, not all 1000
- ‚úÖ `os_signpost` on each page load ‚Äî measurable in Instruments Time Profiler
- ‚úÖ `hasMore` flag prevents unnecessary queries once all data is loaded
- ‚úÖ `isLoadingPage` guard prevents duplicate fetches from rapid scroll events
- ‚ö†Ô∏è The ViewModel holds `ModelContext`, which is not `Sendable`. This is fine as long as the ViewModel stays on the main actor. If the AI marks it `@Sendable`, question it ‚Äî `ModelContext` must be used on a single thread

The performance difference at 1000 entries:

| Metric | VStack + @Query (all) | LazyVStack + Pagination |
|--------|----------------------|------------------------|
| Initial render | ~800ms | ~45ms |
| Memory (entries) | ~12 MB | ~1.5 MB |
| Scroll to row 100 | Immediate (already loaded) | ~20ms (loads page 3) |
| First visible frame | ~800ms | ~45ms |

The trade-off: pagination adds a slight delay when crossing page boundaries. But 20ms is imperceptible. 800ms is not.

**Optimization 2 ‚Äî SwiftData Query Tuning:**

Two fixes here. First, the Insights chart should only fetch the last 30 days:

```swift
// BEFORE ‚Äî fetches ALL entries, filters in Swift
struct InsightsView: View {
    @Query(sort: \MoodEntry.date)
    private var allEntries: [MoodEntry]

    var body: some View {
        let recent = allEntries.filter {
            $0.date > Date.now.addingTimeInterval(-30 * 86400)
        }
        // Chart renders 'recent' but 'allEntries' holds 1000
        // objects in memory for no reason
        Chart(recent) { entry in
            LineMark(
                x: .value("Date", entry.date, unit: .day),
                y: .value("Mood", entry.score)
            )
        }
    }
}
```

```swift
// AFTER ‚Äî filter at the database level with #Predicate
struct InsightsView: View {
    @Query(
        filter: #Predicate<MoodEntry> {
            $0.date > Date.now.addingTimeInterval(-30 * 24 * 60 * 60)
        },
        sort: \MoodEntry.date
    )
    private var recentEntries: [MoodEntry]

    var body: some View {
        NavigationStack {
            ScrollView {
                VStack(spacing: 20) {
                    if recentEntries.isEmpty {
                        ContentUnavailableView(
                            "No Data Yet",
                            systemImage: "chart.line.uptrend.xyaxis",
                            description: Text("Log moods for a few days to see trends.")
                        )
                    } else {
                        moodChart
                        statsSection
                    }
                }
                .padding()
            }
            .navigationTitle("Insights")
        }
    }

    private var moodChart: some View {
        Chart(recentEntries) { entry in
            LineMark(
                x: .value("Date", entry.date, unit: .day),
                y: .value("Mood", entry.score)
            )
            .interpolationMethod(.catmullRom)

            AreaMark(
                x: .value("Date", entry.date, unit: .day),
                y: .value("Mood", entry.score)
            )
            .foregroundStyle(.blue.opacity(0.1))
            .interpolationMethod(.catmullRom)
        }
        .chartYScale(domain: 1...10)
        .frame(height: 200)
    }

    private var statsSection: some View {
        let scores = recentEntries.map(\.score)
        let average = Double(scores.reduce(0, +)) / max(Double(scores.count), 1)

        return VStack(spacing: 12) {
            HStack {
                StatCard(title: "Average", value: String(format: "%.1f", average), systemImage: "number")
                StatCard(title: "Entries", value: "\(recentEntries.count)", systemImage: "list.bullet")
            }
            HStack {
                StatCard(title: "Highest", value: "\(scores.max() ?? 0)", systemImage: "arrow.up")
                StatCard(title: "Lowest", value: "\(scores.min() ?? 0)", systemImage: "arrow.down")
            }
        }
    }
}
```

- ‚úÖ `#Predicate` filters at the database level ‚Äî SQLite returns only matching rows, not all 1000
- ‚úÖ The chart renders at most ~90 data points (3/day for 30 days), which the Charts framework handles without issue
- ‚ùå If the AI filters in Swift after a full fetch, reject it. That defeats the purpose of a database query

Second, for the home screen where we just need a count:

```swift
// BEFORE ‚Äî loads all entries just to count them
@Query private var entries: [MoodEntry]

var body: some View {
    Text("\(entries.count) moods logged")
    // This fetched every MoodEntry into memory just for .count
}

// AFTER ‚Äî fetch only the count
@Observable
final class HomeViewModel {
    var totalEntries = 0

    private let context: ModelContext

    init(context: ModelContext) {
        self.context = context
    }

    func loadStats() {
        let descriptor = FetchDescriptor<MoodEntry>()
        totalEntries = (try? context.fetchCount(descriptor)) ?? 0
    }
}
```

- ‚úÖ `fetchCount()` executes a `SELECT COUNT(*)` ‚Äî no objects materialized, no memory allocated for rows
- ‚úÖ On 1000 entries, the difference is negligible in time but significant in memory: 0 bytes vs ~12 MB of hydrated model objects

**Optimization 3 ‚Äî Image Cache for Mood Photos:**

When entries have photo attachments, the history list decodes image data on every scroll pass. Without caching, scrolling back through 20 photos re-decodes 20 JPEGs from their raw `Data` blobs. This is the most common source of scroll jank in apps with images.

```swift
import UIKit
import os

actor ImageCache {
    static let shared = ImageCache()

    private let cache = NSCache<NSString, UIImage>()
    private var inFlightTasks: [String: Task<UIImage?, Never>] = [:]
    private let signposter = OSSignposter(
        subsystem: "com.moodbit", category: "ImageCache"
    )

    private init() {
        cache.countLimit = 100
        cache.totalCostLimit = 50 * 1024 * 1024  // 50 MB
    }

    func thumbnail(
        for entryID: String,
        data: Data,
        targetSize: CGSize = CGSize(width: 120, height: 120)
    ) async -> UIImage? {
        let cacheKey = "\(entryID)_\(Int(targetSize.width))x\(Int(targetSize.height))" as NSString

        // Check cache first
        if let cached = cache.object(forKey: cacheKey) {
            return cached
        }

        // Deduplicate in-flight requests for the same image
        if let existing = inFlightTasks[cacheKey as String] {
            return await existing.value
        }

        let task = Task<UIImage?, Never> {
            let state = signposter.beginInterval("DecodeThumbnail")
            defer { signposter.endInterval("DecodeThumbnail", state) }

            let options: [CFString: Any] = [
                kCGImageSourceThumbnailMaxPixelSize: max(targetSize.width, targetSize.height),
                kCGImageSourceCreateThumbnailFromImageAlways: true,
                kCGImageSourceCreateThumbnailWithTransform: true
            ]

            guard let source = CGImageSourceCreateWithData(data as CFData, nil),
                  let cgImage = CGImageSourceCreateThumbnailAtIndex(source, 0, options as CFDictionary)
            else { return nil }

            let thumbnail = UIImage(cgImage: cgImage)
            cache.setObject(thumbnail, forKey: cacheKey, cost: data.count)
            return thumbnail
        }

        inFlightTasks[cacheKey as String] = task
        let result = await task.value
        inFlightTasks.removeValue(forKey: cacheKey as String)
        return result
    }

    func evictAll() {
        cache.removeAllObjects()
    }
}
```

- ‚úÖ `actor` provides thread-safe access without manual locking ‚Äî Swift concurrency handles synchronization
- ‚úÖ `CGImageSourceCreateThumbnailAtIndex` decodes directly to the target size ‚Äî never decodes the full-resolution image into memory
- ‚úÖ `NSCache` automatically evicts under memory pressure ‚Äî no manual cleanup needed
- ‚úÖ In-flight deduplication prevents decoding the same image twice when rapid scroll events fire multiple requests
- ‚úÖ `os_signpost` on each decode ‚Äî visible in Instruments to verify cache hits vs misses

Using it in a mood entry row:

```swift
struct MoodEntryRow: View {
    let entry: MoodEntry
    @State private var thumbnail: UIImage?

    var body: some View {
        HStack(spacing: 12) {
            Text(entry.emoji)
                .font(.title)

            VStack(alignment: .leading, spacing: 4) {
                Text(entry.date, format: .dateTime.month().day().hour().minute())
                    .font(.subheadline)
                Text("Mood: \(entry.score)/10")
                    .font(.caption)
                    .foregroundStyle(.secondary)
            }

            Spacer()

            if let thumbnail {
                Image(uiImage: thumbnail)
                    .resizable()
                    .aspectRatio(contentMode: .fill)
                    .frame(width: 44, height: 44)
                    .clipShape(RoundedRectangle(cornerRadius: 8))
            }
        }
        .task(id: entry.id) {
            guard let photoData = entry.photoData else { return }
            thumbnail = await ImageCache.shared.thumbnail(
                for: entry.id.uuidString,
                data: photoData
            )
        }
    }
}
```

- ‚úÖ `.task(id: entry.id)` ‚Äî cancels and restarts if the row is reused for a different entry during scroll
- ‚úÖ The thumbnail is loaded asynchronously ‚Äî no main thread blocking
- ‚úÖ On subsequent appearances (scrolling back), the cache returns instantly

**Optimization 4 ‚Äî Background AI Processing:**

```swift
import SwiftUI
import os

@Observable
final class MoodLogViewModel {
    var isSaving = false
    var savedEntry: MoodEntry?
    var pendingInsight = false

    private let aiService: AIServiceProtocol
    private let fallbackAnalyzer = FallbackAnalyzer()
    private let repository: MoodRepository
    private let signposter = OSSignposter(
        subsystem: "com.moodbit", category: "Performance"
    )

    init(aiService: AIServiceProtocol, repository: MoodRepository) {
        self.aiService = aiService
        self.repository = repository
    }

    func saveMood(score: Int, note: String?, emoji: String) async {
        isSaving = true
        let saveState = signposter.beginInterval("SaveMood")

        // Save immediately with placeholder ‚Äî user sees instant feedback
        let entry = MoodEntry(
            score: score,
            note: note,
            emoji: emoji,
            insight: "Generating your insight...",
            insightSource: .onDevice
        )

        do {
            try repository.save(entry)
            savedEntry = entry
            isSaving = false
            signposter.endInterval("SaveMood", saveState)
        } catch {
            isSaving = false
            signposter.endInterval("SaveMood", saveState)
            return
        }

        // Generate AI insight in the background ‚Äî UI is already updated
        pendingInsight = true
        let insightState = signposter.beginInterval("GenerateInsight")

        let insight = await generateInsight(score: score, note: note)
        entry.insight = insight.text
        entry.insightSource = insight.source

        do {
            try repository.save(entry)
        } catch {
            // Insight update failed ‚Äî entry still saved with placeholder.
            // Not critical. The user's mood is persisted.
        }

        pendingInsight = false
        signposter.endInterval("GenerateInsight", insightState)
    }

    private func generateInsight(
        score: Int,
        note: String?
    ) async -> (text: String, source: InsightSource) {
        do {
            let aiInsight = try await withRetry {
                try await self.aiService.generateInsight(
                    moodScore: score,
                    note: note
                )
            }
            return (aiInsight, .ai)
        } catch {
            let fallback = fallbackAnalyzer.generateFallbackInsight(
                moodScore: score,
                note: note
            )
            return (fallback, .onDevice)
        }
    }
}
```

- ‚úÖ The mood entry saves in under 100ms ‚Äî the user sees confirmation immediately
- ‚úÖ The AI call runs asynchronously after the save ‚Äî no UI freeze, no spinner
- ‚úÖ The entry updates in place when the insight arrives ‚Äî "Generating your insight..." transitions to the real insight
- ‚úÖ Signposts separate save time from insight generation time in Instruments ‚Äî you can see exactly where time goes
- ‚ö†Ô∏è If the AI puts the entire save + insight generation into one `await` chain that blocks the UI until the insight returns, reject it. The save must complete independently

**Optimization 5 ‚Äî Launch Time:**

```swift
import SwiftUI
import SwiftData
import os

@main
struct MoodbitApp: App {
    private let signposter = OSSignposter(
        subsystem: "com.moodbit", category: "Launch"
    )

    var body: some Scene {
        WindowGroup {
            ContentView()
                .onAppear {
                    let state = signposter.beginInterval("AppLaunchToFirstFrame")
                    signposter.endInterval("AppLaunchToFirstFrame", state)
                }
        }
        .modelContainer(for: MoodEntry.self)
    }
}

struct ContentView: View {
    @State private var selectedTab = 0

    var body: some View {
        TabView(selection: $selectedTab) {
            Tab("Log", systemImage: "plus.circle", value: 0) {
                MoodLogView()
            }

            Tab("History", systemImage: "clock", value: 1) {
                MoodHistoryView()
            }

            Tab("Insights", systemImage: "chart.line.uptrend.xyaxis", value: 2) {
                InsightsView()
            }

            Tab("Settings", systemImage: "gear", value: 3) {
                SettingsView()
            }
        }
    }
}
```

SwiftUI's `TabView` does not render off-screen tabs until the user navigates to them. The chart, the history list, and settings cost zero time at launch. Only the Log tab renders.

But watch for this mistake:

```swift
// BAD ‚Äî all ViewModels created at launch regardless of tab
struct ContentView: View {
    @State private var historyVM = MoodHistoryViewModel(...)   // Created at launch
    @State private var insightsVM = InsightsViewModel(...)      // Created at launch
    @State private var settingsVM = SettingsViewModel(...)      // Created at launch

    var body: some View {
        TabView {
            MoodLogView()
            MoodHistoryView(viewModel: historyVM)       // Tab is lazy...
            InsightsView(viewModel: insightsVM)          // ...but the ViewModel
            SettingsView(viewModel: settingsVM)           // already ran init()
        }
    }
}
```

Even though tab content is deferred, the `@State` property wrappers evaluate their initial values when `ContentView` appears. If those ViewModels fetch data in `init()`, you have defeated the purpose of lazy tabs.

**Fix:** Initialize ViewModels inside the tab views themselves, using `.task`:

```swift
struct MoodHistoryView: View {
    @Environment(\.modelContext) private var context
    @State private var viewModel: MoodHistoryViewModel?

    var body: some View {
        Group {
            if let viewModel {
                historyContent(viewModel)
            } else {
                ProgressView()
                    .controlSize(.large)
            }
        }
        .task {
            if viewModel == nil {
                let vm = MoodHistoryViewModel(context: context)
                vm.loadInitialPage()
                viewModel = vm
            }
        }
    }
}
```

- ‚úÖ The ViewModel is `nil` until `.task` fires ‚Äî which only happens when the tab is selected
- ‚úÖ Data fetching happens after the view appears, not during `init()`
- ‚úÖ The `ProgressView` shows for a single frame at most ‚Äî the initial page loads in ~45ms

## Iteration: Measuring and Fixing What Remains

After implementing all five optimizations, there are two common issues that surface during Instruments profiling. Send this follow-up:

```
I applied the performance optimizations. Instruments shows:
1. Initial page load is 45ms (good), but scrolling fast through
   history causes brief hitches when SwiftData fetches the next
   page synchronously on the main thread.
2. The image cache works, but cold scrolling through 20 photos
   still causes visible stutter on first pass.

Fix both:
1. Prefetch the next page when the user scrolls within 10
   entries of the page boundary ‚Äî eliminate visible loading.
2. Add a low-priority background decode queue for images that
   are about to become visible, using onAppear offsets.

Keep os_signpost markers for verification.
```

Here is the prefetching addition to the ViewModel:

```swift
// Add to MoodHistoryViewModel
func prefetchIfNeeded(currentEntry: MoodEntry) {
    guard hasMore, !isLoadingPage else { return }

    guard let index = entries.firstIndex(where: { $0.id == currentEntry.id }) else {
        return
    }

    let threshold = entries.count - 10
    if index >= threshold {
        loadNextPage()
    }
}
```

And update the `LazyVStack` to trigger prefetching:

```swift
LazyVStack(spacing: 0) {
    ForEach(viewModel.entries) { entry in
        MoodEntryRow(entry: entry)
            .padding(.horizontal)
            .padding(.vertical, 6)
            .onAppear {
                viewModel.prefetchIfNeeded(currentEntry: entry)
            }

        Divider()
            .padding(.leading)
    }

    if viewModel.isLoadingPage {
        ProgressView()
            .padding()
    }
}
```

- ‚úÖ When the user scrolls past entry 40 of a 50-entry page, the next page starts loading
- ‚úÖ By the time they reach entry 50, the next 50 are already appended
- ‚úÖ The `ProgressView` at the bottom is rarely visible ‚Äî data arrives before the user scrolls there

## Verify Phase: Instruments Profiling

Open Instruments (Product > Profile in Xcode) and run these tests on a real device or simulator with 700+ test entries:

1. **Launch time** ‚Äî Use the Time Profiler instrument. Measure from `main()` to first frame. Your signpost `AppLaunchToFirstFrame` should show under 1 second for a warm launch. On a cold launch, target under 2 seconds. If it exceeds this, check if any `init()` methods are doing work they should defer.

2. **Scroll performance** ‚Äî Open mood history and scroll quickly through all entries. Use the SwiftUI instrument (available in Xcode 16+). No `body` evaluation should take longer than 16ms ‚Äî that is one frame at 60fps. If you see spikes, check if image decoding is happening on the main thread.

3. **Memory** ‚Äî Open the Allocations instrument. Navigate to mood history, scroll through all entries, navigate back. Memory should return close to baseline. If it grows linearly with scroll distance, you have a retain cycle or unbounded cache. The `NSCache` in `ImageCache` should handle eviction automatically.

4. **Page loading signposts** ‚Äî In Instruments, filter by the "Performance" category. `LoadInitialPage` should be under 50ms. `LoadNextPage` should be under 30ms. `DecodeThumbnail` should show cache hits (near 0ms) on second scroll and cache misses (~5-15ms) on first scroll.

5. **AI processing** ‚Äî Log a mood and watch the Time Profiler. The `SaveMood` signpost should complete in under 100ms. The `GenerateInsight` signpost will be 1-3 seconds but must run on a background thread ‚Äî verify it does not appear on the main thread track.

If any of these fail, you have data to describe the problem precisely. "LoadNextPage takes 200ms and Allocations shows 8MB allocated during the fetch" is a prompt that gets a targeted fix. "It feels slow" is not.

## Final Code

Here is the complete `MoodHistoryView` with all optimizations applied ‚Äî lazy loading, pagination, prefetching, image caching, and deferred ViewModel initialization:

```swift
import SwiftUI
import SwiftData
import os

@Observable
final class MoodHistoryViewModel {
    private(set) var entries: [MoodEntry] = []
    private(set) var hasMore = true
    private(set) var isLoadingPage = false

    private var currentOffset = 0
    private let pageSize = 50
    private let context: ModelContext
    private let signposter = OSSignposter(
        subsystem: "com.moodbit", category: "Performance"
    )

    init(context: ModelContext) {
        self.context = context
    }

    func loadInitialPage() {
        let state = signposter.beginInterval("LoadInitialPage")
        defer { signposter.endInterval("LoadInitialPage", state) }

        currentOffset = 0
        entries = fetchPage(offset: 0)
        hasMore = entries.count == pageSize
    }

    func loadNextPage() {
        guard hasMore, !isLoadingPage else { return }
        isLoadingPage = true

        let state = signposter.beginInterval("LoadNextPage")
        defer {
            signposter.endInterval("LoadNextPage", state)
            isLoadingPage = false
        }

        currentOffset += pageSize
        let newEntries = fetchPage(offset: currentOffset)
        entries.append(contentsOf: newEntries)
        hasMore = newEntries.count == pageSize
    }

    func prefetchIfNeeded(currentEntry: MoodEntry) {
        guard hasMore, !isLoadingPage else { return }

        guard let index = entries.firstIndex(where: {
            $0.id == currentEntry.id
        }) else { return }

        if index >= entries.count - 10 {
            loadNextPage()
        }
    }

    private func fetchPage(offset: Int) -> [MoodEntry] {
        var descriptor = FetchDescriptor<MoodEntry>(
            sortBy: [SortDescriptor(\.date, order: .reverse)]
        )
        descriptor.fetchLimit = pageSize
        descriptor.fetchOffset = offset

        do {
            return try context.fetch(descriptor)
        } catch {
            return []
        }
    }
}

struct MoodHistoryView: View {
    @Environment(\.modelContext) private var context
    @State private var viewModel: MoodHistoryViewModel?

    var body: some View {
        NavigationStack {
            Group {
                if let viewModel {
                    historyContent(viewModel)
                } else {
                    ProgressView()
                        .controlSize(.large)
                }
            }
            .navigationTitle("History")
            .task {
                if viewModel == nil {
                    let vm = MoodHistoryViewModel(context: context)
                    vm.loadInitialPage()
                    viewModel = vm
                }
            }
        }
    }

    private func historyContent(
        _ viewModel: MoodHistoryViewModel
    ) -> some View {
        Group {
            if viewModel.entries.isEmpty {
                ContentUnavailableView(
                    "No Moods Yet",
                    systemImage: "face.smiling",
                    description: Text("Log your first mood to start tracking patterns.")
                )
            } else {
                ScrollView {
                    LazyVStack(spacing: 0) {
                        ForEach(viewModel.entries) { entry in
                            MoodEntryRow(entry: entry)
                                .padding(.horizontal)
                                .padding(.vertical, 6)
                                .onAppear {
                                    viewModel.prefetchIfNeeded(
                                        currentEntry: entry
                                    )
                                }

                            Divider()
                                .padding(.leading)
                        }

                        if viewModel.isLoadingPage {
                            ProgressView()
                                .padding()
                        }
                    }
                }
                .refreshable {
                    viewModel.loadInitialPage()
                }
            }
        }
    }
}

struct MoodEntryRow: View {
    let entry: MoodEntry
    @State private var thumbnail: UIImage?

    var body: some View {
        HStack(spacing: 12) {
            Text(entry.emoji)
                .font(.title)

            VStack(alignment: .leading, spacing: 4) {
                Text(entry.date, format: .dateTime.month().day().hour().minute())
                    .font(.subheadline)
                Text("Mood: \(entry.score)/10")
                    .font(.caption)
                    .foregroundStyle(.secondary)
                if entry.insight != "Generating your insight..." {
                    Text(entry.insight)
                        .font(.caption2)
                        .foregroundStyle(.tertiary)
                        .lineLimit(1)
                }
            }

            Spacer()

            if let thumbnail {
                Image(uiImage: thumbnail)
                    .resizable()
                    .aspectRatio(contentMode: .fill)
                    .frame(width: 44, height: 44)
                    .clipShape(RoundedRectangle(cornerRadius: 8))
            }
        }
        .task(id: entry.id) {
            guard let photoData = entry.photoData else { return }
            thumbnail = await ImageCache.shared.thumbnail(
                for: entry.id.uuidString,
                data: photoData
            )
        }
    }
}
```

Summary of every optimization and its measurable impact:

| Optimization | Before | After | How to Verify |
|---|---|---|---|
| LazyVStack + pagination | All rows created, ~800ms first frame | 50 rows created, ~45ms first frame | Time Profiler, SwiftUI instrument |
| #Predicate on chart query | 1000 entries fetched for 30-day chart | ~90 entries fetched | Allocations instrument |
| fetchCount() for stats | Full object array for count | Zero objects materialized | Allocations instrument |
| Image cache | ~15ms decode per scroll pass per image | 0ms on cache hit, ~10ms on miss | Custom signpost intervals |
| Background AI processing | UI blocks 1-3s during insight generation | Save completes in <100ms | Time Profiler, signposts |
| Deferred ViewModel init | All tabs initialize at launch | Only active tab initializes | Launch signpost interval |

## Checkpoint

Verify these before shipping:

1. The app launches and shows the first tab in under 1 second (warm launch) on your oldest supported device
2. Scrolling through 700+ entries in the history list maintains 60fps with no visible stuttering or jank
3. Memory does not grow unbounded when scrolling through all entries and back ‚Äî check with Allocations instrument
4. Logging a mood shows instant feedback. The save completes before the AI insight arrives
5. The Insights chart loads only the last 30 days of data, verified by checking the `#Predicate` in the `@Query`
6. Instruments signposts show `LoadInitialPage` under 50ms for 50 entries
7. No `VStack` inside `ScrollView` with `ForEach` remains anywhere in the codebase ‚Äî search the project to confirm
8. Photo thumbnails load from cache on second scroll (signpost shows near-zero decode time)
9. The `ProgressView` "loading more" spinner at the bottom of history is rarely visible because prefetching loads the next page before the user reaches it

## Challenge

**Build a memory-aware image cache that adapts to device conditions.** Extend `ImageCache` so that it monitors `ProcessInfo.processInfo.physicalMemory` and system memory pressure notifications (`DispatchSource.makeMemoryPressureSource`). When the system signals memory pressure, the cache should reduce its `totalCostLimit` by 50% and evict the least-recently-used thumbnails. When pressure subsides, restore the original limit. Add a signpost event each time the cache resizes so you can see the adaptation in Instruments.

<details>
<summary>Hint</summary>

Register for memory pressure events using `DispatchSource.makeMemoryPressureSource(eventMask: [.warning, .critical], queue: .main)`. In the event handler, check the `data` property for `.warning` vs `.critical` levels and adjust `NSCache.totalCostLimit` accordingly. Store the original limit so you can restore it later. Use `OSSignposter.emitEvent` to log each resize as a point-in-time event rather than an interval ‚Äî this shows up as a marker in the Instruments timeline.
</details>
